# Engineering Notebook

## 04/06
We made the decision to use the gRPC implementation design problem 1 instead of our own defined protocol implementation using sockets because we feel that the abstraction and transparency of the sending and deciphering messages between server and client was efficient as it was not the focus on this design problem. We also thought that it would be easier to implement this abstraction meant that the code for the gRPC version could be easily kept more cleaner as we implemented replication with several servers and multiple clients. Overall, we went along with the gRPC version to implement replication because of the level of abstraction that hides away the details of message sending and receiving, which would ultimately make having to implement replication of this chat app easier, both as a coder and as a code reviewer.

## 04/07
We first went about trying to implement the system being 2-fault tolerant in the face of crash/failstop failures. We first initialized 3 servers/replicas, which knew each others port numbers such that they could communicate among one another. As per the advice of Varun during section, we decided to use the Master-Slave/Primary-Secondary model for inter-server communicationas this would be the most appropriate model given the scope of this project. In order to test the server's ability to communicate amongst themselves, we first implemented a "ping" function that would send a messsage to other servers, checking to see if the other servers have received the ping. We believe that this will be useful for debugging purposes. Each replica will check periodically to see if any of the other replicas are down. If one is down, we rerun the leader election, which is described more below.

For the leader election process to determien the primary replica, the primary replica was determined as the server with the lowest uuid. This made it the easiest and fastest to select a new primary replica whenever one server went down. We ran the leader election in two cases: first, when all the replicas were connected initially, and two, in the case of a server failture, only when the failed replica was the primary which made things faster in general. 

For the client side of the chat app, the Primary-Secondary model meant that all clients were connected to the primary replica at any moment and communicated with the primary replica to use the chat app. The simple leader election made it such that any client that connected to the app could quickly determine the leader via the lowest uuid. The client also has a ping function that pings the server it thinks is the primary replica periodically. If the primary replica is still the same server, it does nothing and continues pinging. If there is an update on the primary replica, we update the ports accordingly and switch to the new primary replica. The listening for messages from the server is essentially kept the same from design exercise 1 since we're listening to one server, which was an abstraction we believed is appropriate.

## 04/08
We describe some of the debugging problems we ran into while implementing 2-fault tolerance:

We ran into problems trying to add back a server that failed to the client as a now-available server, but the client wasn't able to recognize the added server because the ping function from the server was not being recognized by the client. We later realized that a core functionality of gRPC is that it can't connect a stub back to the same address if the previous instance failed. Thus, when adding back a new server, we made sure that a new stub was opened, and this new channel connected to the clients and other replicas accordingly. When the connection fails, we thus just close the channel instead of trying to work with it again after it comes back alive. This was done by having a global deque that stored system updates such that the client can be informed whenever an update of a new primary replica was added.

Another debugging problem was on the client side as we were adding another thread for pinging the primary replica periodically to check for any status updates. Recall there's another thread that constantly listens for messages, and whenever the ping function recognizes a new primary replica, the listening thread needs to listen to this thread from now on. Previously, in design exercise 1, this was not a problem as therre was only one server to cosntantly listen for messages on. Now, this is not possible. Our solution was to create another gRPC function ChatSingle that the listening thread constantly calls that gets updated whenever a leader election is held. This works since whenever there is an update during the ping call we run a leader election right away.

Till now, we've been using global arrays and data structures to store clients, users, and messages sent. This meant that every time the primary replica died, the remaining replicas would run a leader election, select a new primary replica, but that server would have no information about the registered users, the client IDs, and the messages sent prior to the leader election. This meant clients would need to re-register users, and could not have access to prior messages sent to and from each other. Now, we went about trying to implement the persistant memory storage. We decided to use sqlite databases, initiating one db for each server that would be updated each time a client does something that is stored in the commit log.

## 04/09

Once we got the databases set up, we ran intoa problem with the users table because after every time a client reconnects to the new primary replica, its client ID changes. Thus, a mapping from client to username like we had implemented previously does not work. We thought about completely scrapping the client to username mapping and just hard-coding it by storing the user in the client-side as the state changed, but we realized this was not neccessary, and a better method was to just wait till the user sent something and recording the mapping then, as we now know which client the user is logged in on.

Another thing we noticed is that a user can log onto multiple clients, and we thought it would be best if the user was made aware of this. We want any user to only be logged in on one client at a time, such that it was easy to maintain the mapping of client to user as a surjective function. This would make sending a message to a specific user easy, since we didn't need to worry about sending it a user logged into multiple clients. Thus, we added a warning to the client the user is currently logged in with whenever the user tries to log in using another client, and we logged the user out of the first client whenever this action occurs.
